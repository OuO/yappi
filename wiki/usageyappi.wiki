#summary Usage reference manual for yappi.
= Introduction =

*Using yappi and Interpreting the statistics*
{{{
import yappi
def foo(): pass
yappi.start()
foo()
stats = yappi.get_stats()
for stat in stats: print stat
yappi.stop()
'''
Output:
>python simple.py
name                                 ccnt     ttot       tsub       tavg
simple.py.foo:2                      1        0.000041   0.000041   0.000041   


tname          tid    fname                                schedc   ttot
_MainThread    2884   yappi.py.get_stats:44                1        0.000000   


status     tstart                    fcnt     tcnt     memusage(bytes)
running    Sun Nov 22 11:51:16 200.. 2        1        37932    


        yappi overhead: 0.000054/0.000231(%0.000007)
>
'''
}}}

Note that there are several columns in the profiler stats.

  * *name*: name of the function being profiled
  * *ccnt*: is the total callcount of the function. 
  * *ttot*: total time spent in the function.
  * *tsub*: total time spent in the function excluding sub-calls.
  * *tavg*: is same as ttot / ccnt. Average total time.

the *threads* field gives information about the threads in the profiled application. It shows the last executed function in that thread. In some situations, this information can be used to monitor/debug deadlock issues easily.


the *profiler* field is obvious. It gives information about how many functions are profiled since when.


the last field is the *yappi overhead* field. This requires some explanation. Every profiler has an overhead that is put on the profiled application. As yappi is designed to work with long-running applications, we want to see how much overhead the profiler is putting on to the profiled application. In the example above, yappi overhead is 0.000035 ms where the application run time total is 0.000008 which means the time spent in the profiler is about ~%464 of the runtime of the application. This is too much of course as application has only one function, we have done our best from the start to make this overhead as scalable as possible. You can see different overhead calculations in the examples in this page. 

*Detecting deadlocks:*
{{{
'''
acquire the lock two times to create a deadlock. Lets use 
yappi to detect/debug those kind of deadlock issues. Note 
that not every type of deadlock can be detected/monitored by
yappi of course. But the idea is here to show how to use
some features of yappi for debugging some multithreading issues.
'''
import yappi
import threading
class deadlock_thread(threading.Thread):
    def foo(self):
        for i in xrange(0,2): self.lock.acquire()
    def run(self):
        self.lock = threading.Lock()
        self.foo()
yappi.start() # start the profiler
thr = deadlock_thread() # start the deadlock thread
thr.start()
while 1:
    s = raw_input("yappi>")
    exec s
}}}
So, let's execute the script and type in _yappi.print_stats()_ to print out the stat results. Let's see the output:
{{{
"""
yappi>yappi.print_stats()


name                                 ccnt     ttot       tsub       tavg
threading.py.__init__:39             2        0.000019   0.000019   0.000009
threading.py._set_daemon:415         1        0.000053   0.000027   0.000053
threading.py.isDaemon:624            1        0.000009   0.000009   0.000009
threading.py.currentThread:733       1        0.000017   0.000017   0.000017
threading.py.__init__:396            1        0.000286   0.000122   0.000286
threading.py._note:44                1        0.000008   0.000008   0.000008
threading.py._newname:374            1        0.000018   0.000018   0.000018
threading.py.start:430               1        0.000399   0.000391   0.000399
threading.py.__init__:158            1        0.000058   0.000049   0.000058
threading.py.Condition:153           1        0.000082   0.000024   0.000082


tname          tid    fname                                schedc   ttot
_MainThread    4040   yappi.py.get_stats:44                2        0.000264
deadlock_thr.. 3380   testdeadlock.py.foo:6                1        0.000000 --> last executed function in the deadlock_thread


status     tstart                    fcnt     tcnt     memusage(bytes)
running    Sun Nov 22 12:15:58 200.. 15       2        41620


        yappi overhead: 0.000302/7.880298(%0.000000)

yappi>
"""
}}}
We can regularly check the stats and if no change occurs on the last executed function in the thread, then this naturally is a good sign of a deadlock. 

*A More Complex Usage:*
{{{
'''
 start profiler with built-in profiling set to True. In this example,
 we try to demonstrate how yappi behaves when multiple threads will 
 call recursive functions which is one of the basic unit tests of the 
 profiler.
'''
import time
import yappi
from threading import Thread

NTHREAD = 5
MAXRDEPTH = 10

def foo2(): 
	time.sleep(0.1)

def foo(rdepth):
	if (rdepth == MAXRDEPTH): return
	foo2()
	foo(rdepth+1)	

if __name__ == "__main__":
	yappi.start(True)
	for i in range(NTHREAD):
		thr = Thread(foo(1))
	for it in yappi.get_stats(yappi.SORTTYPE_TTOTAL,
				  yappi.SORTORDER_ASCENDING,
				  yappi.SHOW_ALL):
		print it

"""
projects/yappi$ python usage.py

name                              ccnt   ttot        tsub        tavg
<time.sleep>                      50     4.523953    4.523953    0.090479
testusage2.py.foo:12              50     4.523881    0.001462    0.090478
testusage2.py.foo2:9              45     4.522419    0.001020    0.100498
threading.py._note:44             20     0.000137    0.000137    0.000007
<thread.get_ident>                15     0.000100    0.000100    0.000007
<built-in method acquire>         14     0.000108    0.000108    0.000008
<built-in method acquire>         11     0.000255    0.000255    0.000023
<built-in method release>         11     0.000078    0.000078    0.000007
threading.py.__init__:39          10     0.000096    0.000096    0.000010
threading.py.currentThread:733    10     0.000226    0.000158    0.000023
<built-in method release>         9      0.000064    0.000064    0.000007
threading.py.__stop:539           5      0.000838    0.000167    0.000168
threading.py.run:444              5      0.000055    0.000055    0.000011
threading.py.isDaemon:624         5      0.000038    0.000038    0.000008
threading.py.start:430            5      0.005066    0.000294    0.001013
threading.py._newname:374         5      0.000105    0.000105    0.000021
threading.py.notifyAll:267        5      0.000428    0.000114    0.000086
<thread.allocate_lock>            5      0.000081    0.000081    0.000016
threading.py.__init__:158         5      0.000262    0.000225    0.000052
threading.py.Condition:153        5      0.000375    0.000113    0.000075
threading.py._is_owned:198        5      0.000117    0.000070    0.000023
<thread.start_new_thread>         5      0.002105    0.002105    0.000421
threading.py.notify:249           5      0.000274    0.000124    0.000055
threading.py._set_daemon:415      5      0.000286    0.000124    0.000057
threading.py.__init__:396         5      0.001264    0.000357    0.000253
threading.py.join:579             5      0.000401    0.000194    0.000080
<len>                             5      0.000040    0.000040    0.000008
<range>                           1      0.000009    0.000009    0.000009

threads
Thread 12032:<_yappi.get_stats>
Thread 11456:<built-in method acquire>

profiler
30 functions profiled in 2 threads since Fri Oct 23 11:46:38 2009


        yappi overhead: 0.003215/4.531648(%0.070950)

projects/yappi$
"""
}}}